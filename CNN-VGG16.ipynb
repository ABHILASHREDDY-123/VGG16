{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f911852",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import time\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D,MaxPooling2D,Dropout,InputLayer\n",
    "from tensorflow.keras.utils import to_categorical,plot_model\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import cv2\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe1f2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../germany_dataset/train.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df = df.dropna()\n",
    "df['Rotate'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0b17bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"length\"] = df[\"Roi.X2\"]-df[\"Roi.X1\"]\n",
    "df[\"height\"] = df[\"Roi.Y2\"]-df[\"Roi.Y1\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d929f4db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9034e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Variables declaration to use same code for different datasets\n",
    "num_of_classes = df[\"ClassId\"].nunique()\n",
    "resize_x  = 224\n",
    "resize_y  = 224\n",
    "num_of_channels = 3\n",
    "directory = \"../germany_dataset/\"\n",
    "testdir = \"../germany_dataset/test.csv\"\n",
    "Epochs=25\n",
    "train_length = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dba79bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary Functions\n",
    "def remove_outlier(df,parameter):\n",
    "    Percentile25 = df[parameter].quantile(0.25)\n",
    "    Percentile75 = df[parameter].quantile(0.75)\n",
    "    iqr = Percentile75 - Percentile25\n",
    "    lowerlimit = Percentile25 - 1.5*iqr\n",
    "    upperlimit = Percentile75 + 1.5*iqr\n",
    "    temp1 = df[parameter]>lowerlimit\n",
    "    temp2 = df[parameter]<upperlimit\n",
    "    return df[temp1 & temp2] \n",
    "\n",
    "def get_max_index(arr):\n",
    "    length = len(arr)\n",
    "    mini = 0\n",
    "    value = 0\n",
    "    for i,val in enumerate(arr):\n",
    "        if mini < val :\n",
    "            mini = val\n",
    "            value = i\n",
    "    return value\n",
    "\n",
    "def viewStatistics(df):\n",
    "    #Statistics of Data\n",
    "    print(\"Total Training Examples : \",len(df))\n",
    "    values = df[\"ClassId\"].value_counts()\n",
    "    x_labels = [str(x) for x in range(num_of_classes)]\n",
    "    y_labels = []\n",
    "    for x in range(num_of_classes):\n",
    "        y_labels.append(values[x])\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.bar(x_labels,y_labels,width=0.5)\n",
    "    plt.title('Bar Graph')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def upSampleDataFrame(df,upSampleCount=300):\n",
    "    starting_time = time.time()\n",
    "    classes = {}\n",
    "\n",
    "    for val in range(num_of_classes):\n",
    "        classes[val]=[]\n",
    "\n",
    "    max_repeating = 0\n",
    "\n",
    "    for index,row in df.iterrows():\n",
    "        classes[row.values[6]].append(row.values)\n",
    "\n",
    "    row = []\n",
    "    for i in range(num_of_classes):\n",
    "        length = len(classes[i])\n",
    "        want = upSampleCount - length\n",
    "        for j in range(len(classes[i])):\n",
    "            row.append(classes[i][j])\n",
    "        if(want<=0):\n",
    "            continue\n",
    "        for j in range(want):\n",
    "            select_image = random.randint(0,length-1)\n",
    "            angle = random.randint(0,359)\n",
    "            f = classes[i][select_image].copy()\n",
    "            f[8] = angle\n",
    "            row.append(f)\n",
    "    np.random.shuffle(row)\n",
    "\n",
    "    df = pd.DataFrame(row,columns = df.columns)\n",
    "\n",
    "    ending_time = time.time()\n",
    "    total_time = ending_time - starting_time\n",
    "    total_time/=60\n",
    "    print(\"Total number of images after Upsampling: \", len(df))\n",
    "    print(\"\\n\\nTime taken to upsample images : \",total_time,\" min\")\n",
    "    return df\n",
    "\n",
    "def Predict_for_single_example(model,img):\n",
    "    img  = np.array(img)\n",
    "    img  = tf.convert_to_tensor(img,dtype=float)\n",
    "    img = img/255.0\n",
    "    img = tf.expand_dims(img, axis=0)\n",
    "    probability = model.predict(img)\n",
    "    value = get_max_index(probability[0])\n",
    "    return value\n",
    "    \n",
    "def Predict_for_Multiple_examples(model,images):\n",
    "    img = []\n",
    "    for j in range(len(images)):\n",
    "        img.append(np.array(images[j]))\n",
    "    img = np.array(img)\n",
    "    img = tf.convert_to_tensor(img,dtype=float)\n",
    "    img = img/255.0\n",
    "    probability = model.predict(img,verbose=False)\n",
    "    values = []\n",
    "    for val in probability:\n",
    "        values.append(get_max_index(val))\n",
    "    return values\n",
    "\n",
    "def PredictTest(model,df,start,length):\n",
    "    images = []\n",
    "    y_test = []\n",
    "    length = min(length,len(df)-start)\n",
    "    for i in range(length):\n",
    "        row = df.loc[start+i].values\n",
    "        images.append(Image.open(directory+row[7]).crop((row[2],row[3],row[4],row[5])).rotate(row[8]).resize((resize_x,resize_y)))\n",
    "        y_test.append(row[6])\n",
    "\n",
    "    y_predicted = Predict_for_Multiple_examples(model,images)\n",
    "\n",
    "    return y_test,y_predicted\n",
    "\n",
    "def PredictTest(model,df):\n",
    "    y_test = []\n",
    "    y_predicted=[]\n",
    "    length = len(df)\n",
    "    batchSize = 750\n",
    "    batchCounts = math.ceil(length/batchSize)\n",
    "    for j in range(batchCounts):\n",
    "        images = []\n",
    "        if(j == batchCounts-1):\n",
    "            for row in (df.iloc[j*batchSize:,:].values):\n",
    "                images.append(Image.open(directory+row[7]).crop((row[2],row[3],row[4],row[5])).rotate(row[8]).resize((resize_x,resize_y)))\n",
    "                y_test.append(row[6]) \n",
    "        else :       \n",
    "            for i in range(batchSize):\n",
    "                row = df.loc[i].values\n",
    "                images.append(Image.open(directory+row[7]).crop((row[2],row[3],row[4],row[5])).rotate(row[8]).resize((resize_x,resize_y)))\n",
    "                y_test.append(row[6])\n",
    "\n",
    "        y_predicted.extend(Predict_for_Multiple_examples(model,images))\n",
    "\n",
    "    return y_test,y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870d8ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistics of Data\n",
    "viewStatistics(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e5f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = remove_outlier(df,\"length\")\n",
    "# df = remove_outlier(df,\"height\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8472b351",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Statistics of Data\n",
    "viewStatistics(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61d0af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_length = len(df)\n",
    "print(\"Total Training Examples : \",len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda44fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = upSampleDataFrame(df,2000)\n",
    "viewStatistics(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a50531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Images and there crop according to data given in csv\n",
    "def resize_and_center(image, target_height, target_width):\n",
    "        original_height, original_width= image.size\n",
    "        height_ratio = target_height / original_height\n",
    "        width_ratio = target_width / original_width\n",
    "        resize_ratio = min(height_ratio, width_ratio)\n",
    "        new_height = int(original_height * resize_ratio)\n",
    "        new_width = int(original_width * resize_ratio)\n",
    "        image  = np.array(image)\n",
    "        resized_image = cv2.resize(image, (new_width, new_height))\n",
    "        pad_height = max(0, (target_height - new_height) // 2)\n",
    "        pad_width = max(0, (target_width - new_width) // 2)\n",
    "        centered_image = cv2.copyMakeBorder(resized_image, pad_height, target_height - new_height - pad_height,pad_width, target_width - new_width - pad_width,cv2.BORDER_CONSTANT, value=(255, 255, 255))\n",
    "        return centered_image\n",
    "def showExamples(df):\n",
    "    num_rows = 5\n",
    "    num_cols = 2\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 20))\n",
    "    total_images = []\n",
    "    for i in range(5):\n",
    "        integer = random.randint(0,len(df))\n",
    "        total_images.append(df.iloc[integer].values)\n",
    "    total_images = list(total_images)\n",
    "    for i,val in enumerate(total_images):\n",
    "        row = i\n",
    "        col=0\n",
    "        ax = axes[row, col]\n",
    "        img = Image.open(directory+val[7])\n",
    "        ax.imshow(img)\n",
    "        img = img.crop((val[2],val[3],val[4],val[5]))\n",
    "        img = img.rotate(val[8])\n",
    "        img = resize_and_center(img,resize_x,resize_y)\n",
    "        ax = axes[row,col+1]\n",
    "        ax.imshow(img)\n",
    "    ax.set_title(f'Image {i + 1}')\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e175882",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self,df,size_x,size_y):\n",
    "        self.df = df\n",
    "        self.root = directory\n",
    "        self.resize_x = size_x\n",
    "        self.resize_y = size_y\n",
    "    \n",
    "    def resize_and_center(self,image, target_height, target_width):\n",
    "        original_height, original_width= image.size\n",
    "        height_ratio = target_height / original_height\n",
    "        width_ratio = target_width / original_width\n",
    "        resize_ratio = min(height_ratio, width_ratio)\n",
    "        new_height = int(original_height * resize_ratio)\n",
    "        new_width = int(original_width * resize_ratio)\n",
    "        image  = np.array(image)\n",
    "        resized_image = cv2.resize(image, (new_width, new_height))\n",
    "        pad_height = max(0, (target_height - new_height) // 2)\n",
    "        pad_width = max(0, (target_width - new_width) // 2)\n",
    "        centered_image = cv2.copyMakeBorder(resized_image, pad_height, target_height - new_height - pad_height,pad_width, target_width - new_width - pad_width,cv2.BORDER_CONSTANT, value=(255, 255, 255))\n",
    "        return centered_image\n",
    "\n",
    "    def Do_Crop(self,path,x1,y1,x2,y2,r):\n",
    "        img = Image.open(self.root+path)\n",
    "        img = img.crop((x1,y1,x2,y2))\n",
    "        img = img.rotate(r)\n",
    "        img = self.resize_and_center(img,self.resize_x,self.resize_y)\n",
    "        img = np.array(img,dtype=float)\n",
    "        return img\n",
    "    \n",
    "    def Row_Data(self,row):\n",
    "        self.X.append(self.Do_Crop(row.iloc[7],row.iloc[2],row.iloc[3],row.iloc[4],row.iloc[5],row.iloc[8]))\n",
    "        self.Y.append(int(row.iloc[6]))\n",
    "    \n",
    "    def Get_Data(self,length):\n",
    "        self.X = []\n",
    "        self.Y = []\n",
    "        want = [0]*num_of_classes\n",
    "        for i in range(len(self.df)):\n",
    "            row = self.df.iloc[i]\n",
    "            if(want[int(row.iloc[6])]<length):\n",
    "                want[int(row.iloc[6])] = want[int(row.iloc[6])]+1\n",
    "                self.Row_Data(row)\n",
    "        self.X = np.array(self.X)\n",
    "        self.Y = np.array(self.Y,dtype=int)\n",
    "        \n",
    "    def Get_Data(self):\n",
    "        self.X = []\n",
    "        self.Y = []\n",
    "        for i in range(len(self.df)):\n",
    "            row = self.df.iloc[i]\n",
    "            self.Row_Data(row)\n",
    "        self.X = np.array(self.X)\n",
    "        self.Y = np.array(self.Y,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7069328",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "showExamples(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f6e93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def miniDataTrain(model,df):\n",
    "    data = Data(df,resize_x,resize_y)\n",
    "    data.Get_Data()\n",
    "    X_train = data.X\n",
    "    Y_train = data.Y\n",
    "    X_train = X_train/255.0\n",
    "    history = model.fit(X_train,Y_train,epochs=Epochs,batch_size=32,validation_split=0.1)\n",
    "    return history    \n",
    "\n",
    "def fullDataTrain(model,df,batchsize=2000):\n",
    "    num_train = len(df)\n",
    "    num_mini_trains = math.ceil(num_train/batchsize)\n",
    "    print(\"Total Mini Trainings : \", num_mini_trains)\n",
    "    for i in range(num_mini_trains):\n",
    "        if(num_mini_trains == i+1):\n",
    "            df1 = df.iloc[i*batchsize:,:]\n",
    "            miniDataTrain(model,df1)\n",
    "        else :\n",
    "            df1 = df.iloc[i*batchsize:(i+1)*batchsize,:]\n",
    "            miniDataTrain(model,df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0950f020",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load pre-trained VGG16 model with random weights\n",
    "model = VGG16(weights=None, input_shape=(224, 224, 3), classes=num_of_classes)\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315ec5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef021053",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "starting_time = time.time()\n",
    "\n",
    "fullDataTrain(model,df,860)\n",
    "ending_time = time.time()\n",
    "total_time = ending_time - starting_time\n",
    "total_time/=60\n",
    "\n",
    "print(\"Time taken fit : \",total_time,\" min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efa9533",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "model.save(\"VGG16_MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ae5236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_accuracy = history.history['accuracy']\n",
    "# validation_accuracy = history.history['val_accuracy']\n",
    "# loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ffa10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs  = [x for x in range(Epochs)]\n",
    "# plt.figure(figsize=(10,5))\n",
    "# plt.plot(epochs,training_accuracy,color=\"blue\",label=\"Training Accuracy\")\n",
    "# plt.plot(epochs,validation_accuracy,color=\"red\",label=\"Validation Accuracy\")\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44e83d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs  = [x for x in range(Epochs)]\n",
    "# plt.figure(figsize=(10,5))\n",
    "# plt.plot(epochs,loss,color=\"blue\",label=\"training loss\")\n",
    "# plt.plot(epochs,val_loss,color=\"red\",label=\"validation loss\")\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a710fcbe",
   "metadata": {},
   "source": [
    " ***Test Image Classification and Accuracy Calculation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bafecba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading weights into CNN model \n",
    "# model = tf.keras.models.load_model(\"VGG16_MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5193aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(testdir)\n",
    "print(\"Number of Test Images are \", len(df_test))\n",
    "df_test.dropna()\n",
    "df_test['Rotate']=0\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967dd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewStatistics(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c3e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "showExamples(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d523c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = upSampleDataFrame(df_test,750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90fc234",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952164e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Images Prediction\n",
    "y_test,y_pred = PredictTest(model,df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691433cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.sum(np.diag(confusion)) / np.sum(confusion)\n",
    "print(\"Total Accuracy: \", accuracy*100)\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "classification_rep = classification_report(y_test, y_pred, labels=np.unique(y_pred))\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion)\n",
    "\n",
    "\n",
    "lines = classification_rep.split('\\n')\n",
    "data = []\n",
    "\n",
    "for line in lines[2:-5]:  # Exclude header and footer lines\n",
    "    row_data = line.split()\n",
    "    if len(row_data) > 0:\n",
    "        class_name = row_data[0]\n",
    "        precision = float(row_data[1])\n",
    "        recall = float(row_data[2])\n",
    "        f1_score = float(row_data[3])\n",
    "        support = int(row_data[4])\n",
    "        data.append([class_name, precision, recall, f1_score, support])\n",
    "\n",
    "# Create a DataFrame\n",
    "report = pd.DataFrame(data, columns=['Class', 'Precision', 'Recall', 'F1-Score', 'Support'])\n",
    "# Print the DataFrame\n",
    "print(\"\\n\\n\\n Summarizing the results : \")\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b47f124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing one Random Image from test data \n",
    "test_length = len(df_test)\n",
    "select_row  = np.random.randint(0, test_length-1)\n",
    "row = df_test.iloc[select_row]\n",
    "print(\"Original Value : \",df_test.iloc[select_row,6])\n",
    "img = Image.open(directory+row.iloc[7])\n",
    "img = img.crop((row.iloc[2],row.iloc[3],row.iloc[4],row.iloc[5]))\n",
    "img = img.resize((resize_x,resize_y))\n",
    "plt.imshow(img)\n",
    "img  = np.array(img)\n",
    "img  = tf.convert_to_tensor(img,dtype=float)\n",
    "img = img/255.0\n",
    "img = tf.expand_dims(img, axis=0)\n",
    "probability = model.predict(img)\n",
    "value = get_max_index(probability[0])\n",
    "print(\"Predicted Value : \",value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43ce348",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = []\n",
    "for i in range(num_of_classes):\n",
    "    class_names.append(\"Class \"+str(i))\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion, annot=False, cmap=\"viridis\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
